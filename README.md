# Contrastive-learning-FER

Training a network routinely on a mixed dataset, i.e., a dataset with both masked and non-masked images, will cause the model to perform poorly in one of the cases: non-masked images or masked images. This problem can be tackled using contrastive learning. The contrastive learning paradigm consists of two steps. First, the contrastive learning minimizes the distance between the masked and non-masked feature embeddings generated by the model. Second, expression recognition is learnt. Two versions of the same image are given as input to the network. The first is the original image and the second is a synthetically masked version of the same image. <br/>
  A shared network produces two feature embeddings, one for each image. Mean Square Error loss is used to calculate the distance between these feature embeddings. To train the network for FER, standard cross entropy loss is used.
  
## Methodology
![Picture1](https://user-images.githubusercontent.com/64302305/172059212-92404e10-522f-48c0-9102-7e8298df4e7d.png)

## Results
| ![Results](https://user-images.githubusercontent.com/64302305/172059093-4cc96ab7-4b58-4c64-b4ec-ef22a5be8c11.jpg) |
|:--:| 
| *Results* |
