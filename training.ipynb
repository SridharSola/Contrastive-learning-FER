{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3YsKMFo26RovRio/ijHP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SridharSola/Contrastive-learning-FER/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZrpcRjj5fwZ"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer): \n",
        "  for param_group in optimizer.param_groups: \n",
        "      param_group[\"lr\"] /= 10.\n",
        "\n",
        "def accuracy(out, labels):\n",
        "    _,pred = torch.max(out, dim=1)\n",
        "    return torch.sum(pred==labels).item()\n",
        "\n",
        "def training(MTN,emoClassifierU, emoClassifierM, maskClassifier, train_set, test_set, learning_rate, epochs, lamda, alpha, beta, log, model_save_U, model_save_M, f1_mask = 0, f2_mask = 1):\n",
        "  if torch.cuda.is_available():\n",
        "    MTN.cuda()\n",
        "    emoClassifierU.cuda()\n",
        "    emoClassifierM.cuda()\n",
        "\n",
        "  MTN.train()\n",
        "  emoClassifierU.train()\n",
        "  emoClassifierM.train()\n",
        "  optimizer = torch.optim.Adam([{'params':MTN.parameters(), 'lr': learning_rate}, #\n",
        "                                {'params':emoClassifierU.parameters(), 'lr': learning_rate},\n",
        "                                {'params':emoClassifierM.parameters(), 'lr': learning_rate}\n",
        "                                ]) #added other paras as list\n",
        "  logfile = open(log, 'w')\n",
        "  n_epochs = epochs\n",
        "  print_every = 5\n",
        "  u_test_loss_min = np.Inf\n",
        "  m_test_loss_min = np.Inf\n",
        "  test_loss_m = []\n",
        "  test_loss_u = []\n",
        "  test_acc_maskU = []\n",
        "  test_acc_maskM = []\n",
        "  test_acc_emoU = []\n",
        "  test_acc_emoM = []\n",
        "  train_loss = []\n",
        "  train_acc_mask = []\n",
        "  train_acc_emoU = []\n",
        "  train_acc_emoM = []\n",
        "  Ubest_test_acc_mask = 0.0\n",
        "  Ubest_test_acc_emo = 0.0\n",
        "  Mbest_test_acc_mask = 0.0\n",
        "  Mbest_test_acc_emo = 0.0\n",
        "  total_step = len(train_set)\n",
        "  lrs = []\n",
        "  lrs.append(learning_rate)\n",
        "  mse =nn.MSELoss().cuda()\n",
        "  \n",
        "  bce = torch.nn.BCELoss()\n",
        "  ceU = nn.CrossEntropyLoss()\n",
        "  ceM = nn.CrossEntropyLoss()\n",
        "  m = nn.Sigmoid()\n",
        "  \n",
        "  emoLoss = nn.CrossEntropyLoss().cuda()\n",
        "  maskLoss = nn.BCELoss().cuda()\n",
        "  \n",
        "  \n",
        "  print('\\nTraining starting:\\n', file = logfile)\n",
        "  print('\\nTraining starting:\\n')\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "      running_loss = 0.0\n",
        "      correct_u_mask = 0\n",
        "      correct_u_emo = 0\n",
        "      correct_m_mask = 0\n",
        "      correct_m_emo = 0\n",
        "      total=0\n",
        "      print(f'Epoch {epoch}\\n', file = logfile)\n",
        "      print(f'Epoch {epoch}\\n')\n",
        "      if epoch == 20 or epoch == 28 or epoch==36 or epoch == 50 or epoch == 60:     \n",
        "          #scheduler.step()\n",
        "          adjust_learning_rate(optimizer)\n",
        "          lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "          print(f'Updated lr: {lrs[-1]}\\n', file = logfile)\n",
        "          print(f'Updated lr: {lrs[-1]}\\n')\n",
        "      for batch_idx, (udata_, mdata_, target_) in enumerate(train_set):\n",
        "          mdata_, udata_, target_ = mdata_.to(device), udata_.to(device), target_.to(device)\n",
        "          #print(mdata_.shape)\n",
        "          optimizer.zero_grad()\n",
        "          target_m = torch.ones(target_.shape[0],1).cuda()\n",
        "          target_m = target_m * f2_mask\n",
        "          #print(target_m.shape)\n",
        "          target_u = torch.ones(target_.shape[0], 1).cuda()\n",
        "          target_u = target_u * f1_mask\n",
        "          #First call to backbone net for unmasked images--------(1)\n",
        "          #p = net(udata_)\n",
        "          u_mv, u_ev = MTN(udata_)\n",
        "          #print(u_mv.shape, u_ev.shape)\n",
        "          #print(u_emo_probs)\n",
        "          \n",
        "          #Second call to backbone net for maskd images---------(2)\n",
        "          m_mv, m_ev = MTN(mdata_)\n",
        "          #print(m_mv.shape)\n",
        "          u_emo_probs = emoClassifierU(u_ev)\n",
        "          m_emo_probs = emoClassifierM(m_ev)\n",
        "          #Losses\n",
        "          Lmse = mse(u_ev, m_ev)\n",
        "          emo_lossU = ceU(u_emo_probs, target_)\n",
        "          emo_lossM = ceM(m_emo_probs, target_)\n",
        "          #Total loss is weighted combiation of above losses\n",
        "          loss = alpha*Lmse + beta*(emo_lossM + emo_lossU)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          #Duplicated following as needed\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          _,u_emo_pred = torch.max(u_emo_probs, dim=1)\n",
        "          #print(u_emo_pred)\n",
        "          correct_u_emo += torch.sum(u_emo_pred==target_).item()\n",
        "          _,m_emo_pred = torch.max(m_emo_probs, dim=1)\n",
        "          correct_m_emo += torch.sum(m_emo_pred==target_).item()\n",
        "          \n",
        "\n",
        "          total += target_.size(0)\n",
        "          if (batch_idx) % 20 == 0:\n",
        "              print ('Epoch [{}/{}], Step [{}/{}], Loss(Unmasked): {:.4f},  Loss(Masked): {:.4f}, MSE : {:.4f}, Combined loss: {:.4f} '       \n",
        "                    .format(epoch, n_epochs, batch_idx, total_step,  emo_lossU.item(), emo_lossM.item(), Lmse.item(),loss.item()), file = logfile)\n",
        "              print ('Epoch [{}/{}], Step [{}/{}], Loss(Unmasked): {:.4f},  Loss(Masked): {:.4f}, MSE : {:.4f}, Combined loss: {:.4f} ' \n",
        "                    .format(epoch, n_epochs, batch_idx, total_step,  emo_lossU.item(), emo_lossM.item(), Lmse.item(),loss.item()))\n",
        "      train_acc_mask.append(100 * (correct_u_mask + correct_m_mask) / (total*2))\n",
        "      train_acc_emoU.append(100 * correct_u_emo / total)\n",
        "      train_acc_emoM.append(100 * correct_m_emo / total)\n",
        "      train_loss.append(running_loss/total_step)\n",
        "      print(f'\\ntrain-loss: {np.mean(train_loss):.4f}', file = logfile)\n",
        "      print(f'\\nTrain accuracies: \\n FER on Unmasked: {(100 * correct_u_emo / total):.4f}, FER on Masked: {(100 * correct_m_emo / total):.4f}', file = logfile)\n",
        "      print(f'\\ntrain-loss: {np.mean(train_loss):.4f}')\n",
        "      print(f'\\nTrain accuracies: \\n FER on Unmasked: {(100 * correct_u_emo / total):.4f}, FER on Masked: {(100 * correct_m_emo / total):.4f}') \n",
        "      u_batch_loss = 0\n",
        "      m_batch_loss = 0\n",
        "      total_t=0\n",
        "      u_mask_correct_t=0\n",
        "      m_mask_correct_t=0\n",
        "      u_emo_correct_t = 0\n",
        "      m_emo_correct_t = 0\n",
        "      #Testing\n",
        "      with torch.no_grad():\n",
        "          MTN.eval()\n",
        "          emoClassifierU.eval()\n",
        "          emoClassifierM.eval()\n",
        "\n",
        "          for udata_t, mdata_t, target_t in (test_set):\n",
        "              udata_t, mdata_t, target_t = udata_t.to(device), mdata_t.to(device), target_t.to(device)\n",
        "              target_m = torch.ones(target_t.size(0),1).cuda()\n",
        "              target_m = target_m * f2_mask\n",
        "              target_u = torch.ones(target_t.size(0), 1).cuda()\n",
        "              target_u = target_u * f1_mask\n",
        "              u_mvt, u_evt = MTN(udata_t)\n",
        "              u_emo_probs_t = emoClassifierU(u_evt)\n",
        "\n",
        "              m_mvt, m_evt = MTN(mdata_t)\n",
        "              m_emo_probs_t = emoClassifierM(m_evt)\n",
        "              _,u_emo_pred_t = torch.max(u_emo_probs_t, dim=1)\n",
        "              u_emo_correct_t += torch.sum(u_emo_pred_t==target_t).item()\n",
        "              _,m_emo_pred_t = torch.max(m_emo_probs_t, dim=1)\n",
        "              m_emo_correct_t += torch.sum(m_emo_pred_t==target_t).item()\n",
        "              total_t += target_t.size(0)\n",
        "\n",
        "          test_acc_emoU.append(100 * u_emo_correct_t/total_t)\n",
        "          test_acc_emoM.append(100 * m_emo_correct_t/total_t)\n",
        "          test_loss_u.append(u_batch_loss/len(test_set))\n",
        "          test_loss_m.append(m_batch_loss/len(test_set))\n",
        "          network_learnedU = u_batch_loss < u_test_loss_min\n",
        "          network_learnedM = m_batch_loss < m_test_loss_min\n",
        "          print(f'\\nUnmasked test loss: {np.mean(test_loss_u):.4f}', file = logfile)\n",
        "          print(f'Unmasked Test Accuracies: \\n FER: {(100 * u_emo_correct_t/total_t):.4f}', file = logfile)     #Mask Detection: {(100 * u_mask_correct_t/total_t):.4f},\n",
        "          print(f'Unmasked test loss: {np.mean(test_loss_u):.4f}')\n",
        "          print(f'Unmasked Test Accuracies: \\n FER: {(100 * u_emo_correct_t/total_t):.4f}')\n",
        "          \n",
        "          print(f'\\nMasked test loss: {np.mean(test_loss_m):.4f}', file = logfile)\n",
        "          print(f'Masked Test Accuracies: \\n FER: {(100 * m_emo_correct_t/total_t):.4f}', file = logfile)   #Mask Detection: {(100 * m_mask_correct_t/total_t):.4f},\n",
        "          print(f'Masked test loss: {np.mean(test_loss_m):.4f}')\n",
        "          print(f'Masekd Test Accuracies: \\n FER: {(100 * m_emo_correct_t/total_t):.4f}')\n",
        "          \"\"\"\n",
        "          if Ubest_test_acc_mask < test_acc_maskU[-1]:\n",
        "            #Updating the best test_accuracy obtained for MD on U set\n",
        "            print(\"Best Mask Detection Test Accuracy Updated for Unmasked set\", file = logfile)\n",
        "            print(\"Best Mask Detection Test Accuracy Updated for Unmasked set\")\n",
        "            Ubest_test_acc_mask = test_acc_maskU[-1]\n",
        "            \"\"\"\n",
        "          if Ubest_test_acc_emo < test_acc_emoU[-1]:\n",
        "            #Updating the best test_accuracy obtained\n",
        "            print(\"Best FER Test Accuracy Updated for unmasked set\", file = logfile)\n",
        "            print(\"Best FER Test Accuracy Updated for unmasked set\")\n",
        "            Ubest_test_acc_emo = test_acc_emoU[-1]\n",
        "          \"\"\"\n",
        "          if Mbest_test_acc_mask < test_acc_maskM[-1]:\n",
        "            #Updating the best test_accuracy obtained for MD on M set\n",
        "            print(\"Best Mask Detection Test Accuracy Updated for masked set\", file = logfile)\n",
        "            print(\"Best Mask Detection Test Accuracy Updated for masked set\")\n",
        "            Mbest_test_acc_mask = test_acc_maskM[-1]\n",
        "          \"\"\"\n",
        "          if Mbest_test_acc_emo < test_acc_emoM[-1]:\n",
        "            #Updating the best test_accuracy obtained\n",
        "            print(\"Best FER Test Accuracy Updated for masked set\", file = logfile)\n",
        "            print(\"Best FER Test Accuracy Updated for masked set\")\n",
        "            Mbest_test_acc_emo = test_acc_emoM[-1]\n",
        "          \n",
        "          if network_learnedU:\n",
        "              u_test_loss_min = u_batch_loss\n",
        "              torch.save(net.state_dict(), model_save_U)\n",
        "              print('Improvement-Detected for unmasked, save-model to drive', file = logfile)\n",
        "              print('Improvement-Detected for unmasked, save-model to drive')\n",
        "          if network_learnedM:\n",
        "              m_test_loss_min = m_batch_loss\n",
        "              torch.save(net.state_dict(), model_save_M)\n",
        "              print('Improvement-Detected for masked, save-model to drive', file = logfile)\n",
        "              print('Improvement-Detected for masked, save-model to drive')\n",
        "\n",
        "\n",
        "      MTN.train()\n",
        "      emoClassifierU.train()\n",
        "      emoClassifierM.train()\n",
        "\n",
        "  print(\"The best Mask Detection test accuracy obtained on Unmasked images was: \", Ubest_test_acc_mask)\n",
        "  print(\"The best FER test accuracy obtained on Unmasked images was: \", Ubest_test_acc_emo)\n",
        "  print(\"The best Mask Detection test accuracy obtained on Masked images was: \", Mbest_test_acc_mask)\n",
        "  print(\"The best FER test accuracy obtained on Masked images was: \", Mbest_test_acc_emo)\n",
        "  #End of training"
      ]
    }
  ]
}